from itertools import product

CONFIGS = [
  # Represents 64 B records, 3200 bytes per page +/- 640 bytes
  {
    "records_per_page_goal": 50,
    "records_per_page_delta": 10,
    "max_page_records": 60,
  },
  # Represents 1024 B records, 2048 bytes per page +/- 1024 bytes
  {
    "records_per_page_goal": 2,
    "records_per_page_delta": 1,
    "max_page_records": 3,
  },
]

COMMON_OPTS = {
  "max_overflow_frac": 0.5,
  "initial_dataset_frac": 0.5,
  "merge_times": 1000,
  "merge_trigger_period": 100000,
  "slope_epsilon": 1e3,
  "seed": 42,
  "reorg_at_length": 3,
}

CUSTOM_DATASET_PATH = "/spinning/kipf/bourbon_datasets/"

CUSTOM_DATASETS = [
  {"name": "amzn", "file": "amazon_reviews.txt", "workload": "long-amzn.yml"},
  {"name": "osm", "file": "osm_ny.txt", "workload": "long-osm.yml"},
]

WORKLOAD_PATH = "../scripts/sim_insert_scan_merge/workloads/"

run_experiment_group(
  name="segments",
  run="./run_segments.sh",
  experiments=[
    ExperimentInstance(
      name="{}-{}-{}".format(
        dataset["name"],
        config["records_per_page_goal"],
        config["records_per_page_delta"],
      ),
      options={
        **COMMON_OPTS,
        **config,
        "workload_config": WORKLOAD_PATH + dataset["workload"],
        "custom_dataset": CUSTOM_DATASET_PATH + dataset["file"],
      },
      parallelizable=True,
    )
    for config, dataset in product(CONFIGS, CUSTOM_DATASETS)
  ] + [
    ExperimentInstance(
      name="uniform-{}-{}".format(
        config["records_per_page_goal"],
        config["records_per_page_delta"],
      ),
      options={
        **COMMON_OPTS,
        **config,
        "workload_config": WORKLOAD_PATH + "long.yml",
      },
      parallelizable=True,
    )
    for config in CONFIGS
  ],
)

run_experiment_group(
  name="chains",
  run="./run_segments.sh",
  experiments=[
    ExperimentInstance(
      name="chains-{}-{}".format(
        dataset["name"],
        config["records_per_page_goal"],
      ),
      args=["--chains"],
      options={
        **COMMON_OPTS,
        **config,
        "workload_config": WORKLOAD_PATH + dataset["workload"],
        "custom_dataset": CUSTOM_DATASET_PATH + dataset["file"],
      },
      parallelizable=True,
    )
    for config, dataset in product(CONFIGS, CUSTOM_DATASETS)
  ] + [
    ExperimentInstance(
      name="chains-uniform-{}".format(
        config["records_per_page_goal"],
      ),
      args=["--chains"],
      options={
        **COMMON_OPTS,
        **config,
        "workload_config": WORKLOAD_PATH + "long.yml",
      },
      parallelizable=True,
    )
    for config in CONFIGS
  ],
)
